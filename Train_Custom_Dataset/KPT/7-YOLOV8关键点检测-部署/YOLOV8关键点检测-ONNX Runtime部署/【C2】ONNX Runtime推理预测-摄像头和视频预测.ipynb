{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX Runtime推理预测-摄像头和视频预测\n",
    "\n",
    " 2023-5-15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `注意，本代码需要在本地，连接摄像头运行，不能在云GPU平台运行`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入工具包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import onnxruntime\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.yolo.data.augment import LetterBox\n",
    "from ultralytics.yolo.utils import ops\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "# 有 GPU 就用 GPU，没有就用 CPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 载入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpts_shape = [3, 3] # 关键点 shape\n",
    "bbox_name = 'sjb_rect' # 目标检测框的类别名称"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建ONNX Runtime的InferenceSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_session = onnxruntime.InferenceSession('checkpoint/Triangle_215_yolov8l_pretrain.onnx', providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获得ONNX模型输入层和数据维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = ort_session.get_inputs()\n",
    "input_name = [model_input[0].name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = model_input[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_height, input_width = input_shape[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获得ONNX模型输出层和数据维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = ort_session.get_outputs()\n",
    "output_name = [model_output[0].name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_shape = model_output[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 框（rectangle）可视化配置\n",
    "bbox_color = (150, 0, 0)             # 框的 BGR 颜色\n",
    "bbox_thickness = 2                   # 框的线宽\n",
    "\n",
    "# 框类别文字\n",
    "bbox_labelstr = {\n",
    "    'font_size':1,         # 字体大小\n",
    "    'font_thickness':2,    # 字体粗细\n",
    "    'offset_x':0,          # X 方向，文字偏移距离，向右为正\n",
    "    'offset_y':-10,        # Y 方向，文字偏移距离，向下为正\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 关键点 BGR 配色\n",
    "kpt_color_map = {\n",
    "    0:{'name':'angle_30', 'color':[255, 0, 0], 'radius':6},      # 30度角点\n",
    "    1:{'name':'angle_60', 'color':[0, 255, 0], 'radius':6},      # 60度角点\n",
    "    2:{'name':'angle_90', 'color':[0, 0, 255], 'radius':6},      # 90度角点\n",
    "}\n",
    "\n",
    "# 点类别文字\n",
    "kpt_labelstr = {\n",
    "    'font_size':1.5,             # 字体大小\n",
    "    'font_thickness':3,       # 字体粗细\n",
    "    'offset_x':10,             # X 方向，文字偏移距离，向右为正\n",
    "    'offset_y':0,            # Y 方向，文字偏移距离，向下为正\n",
    "}\n",
    "\n",
    "# 骨架连接 BGR 配色\n",
    "skeleton_map = [\n",
    "    {'srt_kpt_id':0, 'dst_kpt_id':1, 'color':[196, 75, 255], 'thickness':2},        # 30度角点-60度角点\n",
    "    {'srt_kpt_id':0, 'dst_kpt_id':2, 'color':[180, 187, 28], 'thickness':2},        # 30度角点-90度角点\n",
    "    {'srt_kpt_id':1, 'dst_kpt_id':2, 'color':[47,255, 173], 'thickness':2},         # 60度角点-90度角点\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 逐帧处理函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(img_bgr):\n",
    "    \n",
    "    '''\n",
    "    输入摄像头画面 bgr-array，输出图像 bgr-array\n",
    "    '''\n",
    "    \n",
    "    # 记录该帧开始处理的时间\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 预处理-缩放图像尺寸\n",
    "    img_bgr_640 = cv2.resize(img_bgr, [input_height, input_width])\n",
    "    img_rgb_640 = img_bgr_640[:,:,::-1]\n",
    "    # 预处理-归一化\n",
    "    input_tensor = img_rgb_640 / 255\n",
    "    # 预处理-构造输入 Tensor\n",
    "    input_tensor = np.expand_dims(input_tensor, axis=0) # 加 batch 维度\n",
    "    input_tensor = input_tensor.transpose((0, 3, 1, 2)) # N, C, H, W\n",
    "    input_tensor = np.ascontiguousarray(input_tensor)   # 将内存不连续存储的数组，转换为内存连续存储的数组，使得内存访问速度更快\n",
    "    input_tensor = torch.from_numpy(input_tensor).to(device).float() # 转 Pytorch Tensor\n",
    "    # input_tensor = input_tensor.half() # 是否开启半精度，即 uint8 转 fp16，默认转 fp32 \n",
    "\n",
    "    # ONNX Runtime 推理预测\n",
    "    ort_output = ort_session.run(output_name, {input_name[0]: input_tensor.numpy()})[0]\n",
    "    # 转 Tensor\n",
    "    preds = torch.Tensor(ort_output)\n",
    "\n",
    "    # 后处理-置信度过滤、NMS过滤\n",
    "    preds = ops.non_max_suppression(preds, conf_thres=0.25, iou_thres=0.7, nc=1)\n",
    "    pred = preds[0]\n",
    "    \n",
    "    # 解析目标检测预测结果\n",
    "    pred_det = pred[:, :6].cpu().numpy()\n",
    "    num_bbox = len(pred_det)\n",
    "    bboxes_cls = pred_det[:, 5] # 类别\n",
    "    bboxes_conf = pred_det[:, 4] # 置信度\n",
    "    \n",
    "    # 目标检测框 XYXY 坐标\n",
    "    # 还原为缩放之前原图上的坐标\n",
    "    pred_det[:, 0] = pred_det[:, 0] * x_ratio\n",
    "    pred_det[:, 1] = pred_det[:, 1] * y_ratio\n",
    "    pred_det[:, 2] = pred_det[:, 2] * x_ratio\n",
    "    pred_det[:, 3] = pred_det[:, 3] * y_ratio\n",
    "    pred_det[pred_det<0] = 0 # 把小于零的抹成零\n",
    "    bboxes_xyxy = pred_det[:, :4].astype('uint32')\n",
    "\n",
    "    # 解析关键点检测预测结果\n",
    "    pred_kpts = pred[:, 6:].view(len(pred), kpts_shape[0], kpts_shape[1])\n",
    "    bboxes_keypoints = pred_kpts.cpu().numpy()\n",
    "    # 还原为缩放之前原图上的坐标\n",
    "    bboxes_keypoints[:,:,0] = bboxes_keypoints[:,:,0] * x_ratio\n",
    "    bboxes_keypoints[:,:,1] = bboxes_keypoints[:,:,1] * y_ratio\n",
    "    bboxes_keypoints = bboxes_keypoints.astype('uint32')\n",
    "    \n",
    "    # OpenCV可视化\n",
    "    for idx in range(num_bbox): # 遍历每个框\n",
    "\n",
    "        # 获取该框坐标\n",
    "        bbox_xyxy = bboxes_xyxy[idx] \n",
    "        \n",
    "        # pdb.set_trace()\n",
    "\n",
    "        # 获取框的预测类别（对于关键点检测，只有一个类别）\n",
    "        bbox_label = bbox_name\n",
    "\n",
    "        # 画框\n",
    "        img_bgr = cv2.rectangle(img_bgr, (bbox_xyxy[0], bbox_xyxy[1]), (bbox_xyxy[2], bbox_xyxy[3]), bbox_color, bbox_thickness)\n",
    "\n",
    "        # 写框类别文字：图片，文字字符串，文字左上角坐标，字体，字体大小，颜色，字体粗细\n",
    "        img_bgr = cv2.putText(img_bgr, bbox_label, (bbox_xyxy[0]+bbox_labelstr['offset_x'], bbox_xyxy[1]+bbox_labelstr['offset_y']), cv2.FONT_HERSHEY_SIMPLEX, bbox_labelstr['font_size'], bbox_color, bbox_labelstr['font_thickness'])\n",
    "\n",
    "        bbox_keypoints = bboxes_keypoints[idx] # 该框所有关键点坐标和置信度\n",
    "\n",
    "        # 画该框的骨架连接\n",
    "        for skeleton in skeleton_map:\n",
    "\n",
    "            # 获取起始点坐标\n",
    "            srt_kpt_id = skeleton['srt_kpt_id']\n",
    "            srt_kpt_x = bbox_keypoints[srt_kpt_id][0]\n",
    "            srt_kpt_y = bbox_keypoints[srt_kpt_id][1]\n",
    "\n",
    "            # 获取终止点坐标\n",
    "            dst_kpt_id = skeleton['dst_kpt_id']\n",
    "            dst_kpt_x = bbox_keypoints[dst_kpt_id][0]\n",
    "            dst_kpt_y = bbox_keypoints[dst_kpt_id][1]\n",
    "\n",
    "            # 获取骨架连接颜色\n",
    "            skeleton_color = skeleton['color']\n",
    "\n",
    "            # 获取骨架连接线宽\n",
    "            skeleton_thickness = skeleton['thickness']\n",
    "\n",
    "            # 画骨架连接\n",
    "            img_bgr = cv2.line(img_bgr, (srt_kpt_x, srt_kpt_y),(dst_kpt_x, dst_kpt_y),color=skeleton_color,thickness=skeleton_thickness)\n",
    "\n",
    "        # 画该框的关键点\n",
    "        for kpt_id in kpt_color_map:\n",
    "\n",
    "            # 获取该关键点的颜色、半径、XY坐标\n",
    "            kpt_color = kpt_color_map[kpt_id]['color']\n",
    "            kpt_radius = kpt_color_map[kpt_id]['radius']\n",
    "            kpt_x = bbox_keypoints[kpt_id][0]\n",
    "            kpt_y = bbox_keypoints[kpt_id][1]\n",
    "\n",
    "            # 画圆：图片、XY坐标、半径、颜色、线宽（-1为填充）\n",
    "            img_bgr = cv2.circle(img_bgr, (kpt_x, kpt_y), kpt_radius, kpt_color, -1)\n",
    "\n",
    "            # 写关键点类别文字：图片，文字字符串，文字左上角坐标，字体，字体大小，颜色，字体粗细\n",
    "            kpt_label = str(kpt_id) # 写关键点类别 ID（二选一）\n",
    "            # kpt_label = str(kpt_color_map[kpt_id]['name']) # 写关键点类别名称（二选一）\n",
    "            img_bgr = cv2.putText(img_bgr, kpt_label, (kpt_x+kpt_labelstr['offset_x'], kpt_y+kpt_labelstr['offset_y']), cv2.FONT_HERSHEY_SIMPLEX, kpt_labelstr['font_size'], kpt_color, kpt_labelstr['font_thickness'])\n",
    "            \n",
    "    # 记录该帧处理完毕的时间\n",
    "    end_time = time.time()\n",
    "    # 计算每秒处理图像帧数FPS\n",
    "    FPS = 1/(end_time - start_time)\n",
    "\n",
    "    # 在画面上写字：图片，字符串，左上角坐标，字体，字体大小，颜色，字体粗细\n",
    "    FPS_string = 'FPS  {:.2f}'.format(FPS) # 写在画面上的字符串\n",
    "    img_bgr = cv2.putText(img_bgr, FPS_string, (25, 60), cv2.FONT_HERSHEY_SIMPLEX, 1.25, (255, 0, 255), 2)\n",
    "    \n",
    "    return img_bgr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 摄像头拍摄单帧画面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取摄像头，0为电脑默认摄像头，1为外接摄像头\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# 拍照\n",
    "time.sleep(3) # 运行本代码后等几秒拍照\n",
    "# 从摄像头捕获一帧画面\n",
    "success, frame = cap.read()\n",
    "\n",
    "cap.release() # 关闭摄像头\n",
    "cv2.destroyAllWindows() # 关闭图像窗口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X 方向 图像缩放比例\n",
    "x_ratio = frame.shape[1] / input_width\n",
    "# Y 方向 图像缩放比例\n",
    "y_ratio = frame.shape[0] / input_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frame[:,:,::-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 单帧画面关键点检测预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_bgr = process_frame(frame)\n",
    "\n",
    "plt.imshow(img_bgr[:,:,::-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 摄像头实时画面逐帧处理（模板）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调用摄像头逐帧实时处理模板\n",
    "# 不需修改任何代码，只需修改process_frame函数即可\n",
    "#  2021-7-8\n",
    "\n",
    "# 导入opencv-python\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# 获取摄像头，传入0表示获取系统默认摄像头\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "# 打开cap\n",
    "cap.open(0)\n",
    "\n",
    "# 无限循环，直到break被触发\n",
    "while cap.isOpened():\n",
    "    \n",
    "    # 获取画面\n",
    "    success, frame = cap.read()\n",
    "    \n",
    "    if not success: # 如果获取画面不成功，则退出\n",
    "        print('获取画面不成功，退出')\n",
    "        break\n",
    "    \n",
    "    ## 逐帧处理\n",
    "    try:\n",
    "        frame = process_frame(frame)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # 展示处理后的三通道图像\n",
    "    cv2.imshow('my_window',frame)\n",
    "    \n",
    "    key_pressed = cv2.waitKey(60) # 每隔多少毫秒毫秒，获取键盘哪个键被按下\n",
    "    # print('键盘上被按下的键：', key_pressed)\n",
    "\n",
    "    if key_pressed in [ord('q'),27]: # 按键盘上的q或esc退出（在英文输入法下）\n",
    "        break\n",
    "    \n",
    "# 关闭摄像头\n",
    "cap.release()\n",
    "\n",
    "# 关闭图像窗口\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 按`q`键或`Esc`键关闭画面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
